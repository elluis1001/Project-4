{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Snq4iq_JOB4T"
      },
      "source": [
        "# PART 1 : Install Dependencies & Run Spark Session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpCRBcqtN5lH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf5bd25c-eb30-49e1-cdc4-d179c1c7853b"
      },
      "source": [
        "#install pyspark\n",
        "! pip install pyspark\n",
        "\n",
        "from pyspark.sql.functions import when, col"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread _colab_inspector_thread:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/colab/_debugpy.py\", line 64, in inspector_thread\n",
            "    _variable_inspector.run(shell, time)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/colab/_variable_inspector.py\", line 27, in run\n",
            "    globals().clear()\n",
            "TypeError: 'module' object is not callable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.0)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNZoOuDqOdxX"
      },
      "source": [
        "#create a sparksession\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"spark\").getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sG3MLXlOews"
      },
      "source": [
        "# PART 2: Clone & Explore dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Uh5H7_KOoSL"
      },
      "source": [
        "#clone the diabetes dataset from the github repository\n",
        "# if you get error saying \"Project-4 directory already exists, move to next cell\"\n",
        "! git clone https://github.com/elluis1001/Project-4/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcqwJRxVOutr"
      },
      "source": [
        "#check if the dataset exists\n",
        "! ls /content/Project-4/Luis/Dataset/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ST1rFFOlOu8s"
      },
      "source": [
        "#create spark dataframe\n",
        "df_diabetes_data = spark.read.csv(\"/content/Project-4/Luis/Dataset/diabetes_prediction_dataset.csv\", header=True, inferSchema=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiJm-pmROvKd"
      },
      "source": [
        "#display the dataframe\n",
        "df_diabetes_data.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#show amount of rows\n",
        "df_diabetes_data.count()"
      ],
      "metadata": {
        "id": "MKF7kv1AI2pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ulqkuz8aOvV6"
      },
      "source": [
        "#print the schema\n",
        "df_diabetes_data.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpZlF2S2Ovgw"
      },
      "source": [
        "#count the total no. of diabetic and non-diabetic class (values of 1 indicating the presence of diabetes and 0 indicating the absence of diabetes)\n",
        "print((df_diabetes_data.count(), len(df_diabetes_data.columns)))\n",
        "df_diabetes_data.groupBy('diabetes').count().show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#count the total no. of gender types\n",
        "print((df_diabetes_data.count(), len(df_diabetes_data.columns)))\n",
        "df_diabetes_data.groupBy('gender').count().show()"
      ],
      "metadata": {
        "id": "3f2sAuuh9iY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check to see if there are any empty values in the 'gender' column\n",
        "df_diabetes_data[df_diabetes_data['gender'] == '']"
      ],
      "metadata": {
        "id": "muPOXP7dF2Jl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NewCNZEMOvtM"
      },
      "source": [
        "#get the summary statistics\n",
        "df_diabetes_data.describe().show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZerPOR-OyjQ"
      },
      "source": [
        "# PART 3: Data Cleaning & Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-KkJvV_PFFU"
      },
      "source": [
        "#check for null values\n",
        "for col in df_diabetes_data.columns:\n",
        "  print(col + \":\", df_diabetes_data[df_diabetes_data[col].isNull()].count())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJsbgwZMPFQC"
      },
      "source": [
        "#look for the unnecessary values present\n",
        "def count_zeros():\n",
        "  columns_list = [\"age\", \"bmi\", \"HbA1c_level\", \"blood_glucose_level\"]\n",
        "  for i in columns_list:\n",
        "    print(i+\":\",df_diabetes_data[df_diabetes_data[i]==0].count())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcXTErb9PFbo"
      },
      "source": [
        "count_zeros()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0bk0Ps_PFwk"
      },
      "source": [
        "#display the dataframe\n",
        "df_diabetes_data.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#drop the 'other' rows in the gender columns\n",
        "string_to_remove = \"Other\"\n",
        "df_diabetes_data = df_diabetes_data[df_diabetes_data['Gender'] != string_to_remove]"
      ],
      "metadata": {
        "id": "E1k77q7hKhIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#count the total no. of gender types\n",
        "print((df_diabetes_data.count(), len(df_diabetes_data.columns)))\n",
        "df_diabetes_data.groupBy('gender').count().show()"
      ],
      "metadata": {
        "id": "OXDmlg6KZgTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#count the total no. of smoker/non-smoker types\n",
        "print((df_diabetes_data.count(), len(df_diabetes_data.columns)))\n",
        "df_diabetes_data.groupBy('smoking_history').count().show()"
      ],
      "metadata": {
        "id": "xwwTUAJLZ72A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#drop the 'other' rows in the gender columns\n",
        "string_to_remove_1= \"No Info\"\n",
        "df_diabetes_data = df_diabetes_data[df_diabetes_data['smoking_history'] != string_to_remove_1]"
      ],
      "metadata": {
        "id": "KdN7OCA1cDnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#count the total no. of smoker/non-smoker types\n",
        "print((df_diabetes_data.count(), len(df_diabetes_data.columns)))\n",
        "df_diabetes_data.groupBy('smoking_history').count().show()"
      ],
      "metadata": {
        "id": "ZbxmgHOFcoEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#count the total no. of gender types\n",
        "print((df_diabetes_data.count(), len(df_diabetes_data.columns)))\n",
        "df_diabetes_data.groupBy('gender').count().show()"
      ],
      "metadata": {
        "id": "ZKJc4_sLh_pJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#assign in the 'gender'column 'Female' = 0, and 'Male' = 1\n",
        "from pyspark.sql.functions import when, col\n",
        "df_diabetes_data = df_diabetes_data.withColumn(\"gender\",\n",
        "    when(col(\"gender\") == \"Female\", 0).\n",
        "    when(col(\"gender\") == \"Male\", 1).\n",
        "    otherwise(col(\"gender\"))\n",
        ")\n",
        "df_diabetes_data.show()"
      ],
      "metadata": {
        "id": "ZlK0I77Di1Yq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#assign in the 'smoking_history': \"never\" = 0, \"ever\" = 1, \"not current\" = 2, \"current\" = 3, \"former\" = 4\n",
        "df_diabetes_data = df_diabetes_data.withColumn(\"smoking_history\",\n",
        "    when(col(\"smoking_history\") == \"never\", 0).\n",
        "    when(col(\"smoking_history\") == \"ever\", 1).\n",
        "    when(col(\"smoking_history\") == \"not current\", 2).\n",
        "    when(col(\"smoking_history\") == \"current\", 3).\n",
        "    when(col(\"smoking_history\") == \"former\", 4).\n",
        "    otherwise(col(\"smoking_history\"))\n",
        ")\n",
        "df_diabetes_data.show()"
      ],
      "metadata": {
        "id": "j3RHqrEwlS_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOgSTdBpPs7G"
      },
      "source": [
        "# PART 4: Correlation Analysis & Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gender and smoking_history needs to be converted to float data type for model to work\n",
        "df_diabetes_data = df_diabetes_data.withColumn(\"gender\", col(\"gender\").cast('float'))\n",
        "df_diabetes_data = df_diabetes_data.withColumn(\"smoking_history\", col(\"smoking_history\").cast('float'))\n",
        "df_diabetes_data.show()\n"
      ],
      "metadata": {
        "id": "PVQ4iahSjL63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Eq6jdcFP_3C"
      },
      "source": [
        "#find the correlation among the set of input & output variables\n",
        "for i in df_diabetes_data.columns:\n",
        "  print(\"Correlation to outcome for {} is {}\".format(i, df_diabetes_data.stat.corr(\"diabetes\",i)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fl7Edj-OQACn"
      },
      "source": [
        "#feature selection\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "assembler = VectorAssembler(inputCols = ['gender', 'age', 'hypertension', 'heart_disease',\n",
        "                                         'smoking_history', 'bmi', 'HbA1c_level', 'blood_glucose_level'], outputCol='features')\n",
        "output_data = assembler.transform(df_diabetes_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJKrfqdaQAOy"
      },
      "source": [
        "#print the schema\n",
        "output_data.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FURl7qESQAaQ"
      },
      "source": [
        "#display dataframe\n",
        "output_data.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fSjOdfyQA99"
      },
      "source": [
        "# PART 5: Split Dataset & Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F89--FiVQQJn"
      },
      "source": [
        "#create final data\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "final_data = output_data.select('features','diabetes')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKpm5912Qji_"
      },
      "source": [
        "#print schema of final data\n",
        "final_data.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_Nom7aZQjuN"
      },
      "source": [
        "#split the dataset ; build the model\n",
        "train, test = final_data.randomSplit([0.7, 0.3])\n",
        "models = LogisticRegression(labelCol= 'diabetes')\n",
        "model = models.fit(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OljO2HcIQj7E"
      },
      "source": [
        "#summary of the model\n",
        "summary = model.summary\n",
        "summary.predictions.describe().show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfaD_vzfQkah"
      },
      "source": [
        "# PART 6: Evaluate and Save the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHC5Erq7Q4QN"
      },
      "source": [
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "\n",
        "predictions = model.evaluate(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBltVqoNQ4cM"
      },
      "source": [
        "predictions.predictions.show(100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4BHCxCiQ4l-"
      },
      "source": [
        "evaluator = BinaryClassificationEvaluator(rawPredictionCol= 'rawPrediction', labelCol='diabetes')\n",
        "evaluator.evaluate(model.transform(test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERpRUFOHQ4x5"
      },
      "source": [
        "# save model\n",
        "model.save(\"model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zSA9_KCQ47W"
      },
      "source": [
        "# load saved model back to the environment\n",
        "from pyspark.ml.classification import LogisticRegressionModel\n",
        "\n",
        "model = LogisticRegressionModel.load('model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iznukr-xRANo"
      },
      "source": [
        "# PART 7: Prediction on New Data with the saved model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBq2hq27RdHB"
      },
      "source": [
        "#create a new spark dataframe\n",
        "test_df = spark.read.csv('/content/Project-4/Luis/Dataset/diabetes_test_dataset.csv', header=True, inferSchema=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "co8K0NZsRdQB"
      },
      "source": [
        "#print the schema\n",
        "test_df.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7jtGf4lRdaz"
      },
      "source": [
        "#create an additional feature merged column\n",
        "test_data = assembler.transform(test_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kd1glzOnRdkq"
      },
      "source": [
        "#print the schema\n",
        "test_data.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40Dck7K_Rdxh"
      },
      "source": [
        "#use model to make predictions\n",
        "results = model.transform(test_data)\n",
        "results.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHpfS2SjRd7s"
      },
      "source": [
        "#display the predictions\n",
        "results.select('features','rawPrediction','probability','prediction').show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PART 8: Host a Flask App which will take subjects parameters and return probablity and prediction on being diabetic or not based on ML model above"
      ],
      "metadata": {
        "id": "IKwLb4u2OB-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import dependencies to run Flask app and host it on publicly accessible colab URL\n",
        "from flask import *\n",
        "from google.colab import output\n",
        "from google.colab.output import eval_js"
      ],
      "metadata": {
        "id": "f5MRzVzRGdLn"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize Flask app\n",
        "app=Flask(__name__)\n"
      ],
      "metadata": {
        "id": "9Wj4Xo3ZGkXY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Static Root API for Diabetes Prediction Model\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return 'Root API for Diabetes Prediction Model'\n",
        "\n",
        "# Dynamic API that will take parameters of subject through Web UI and leverage ML Model above to return probability & prediction for being diabetic\n",
        "@app.route('/api/v1.0/predict/<gender>/<age>/<hypertension>/<heart_disease>/<smoking_history>/<bmi>/<HbA1c_level>/<blood_glucose_level>')\n",
        "def predict(gender,age,hypertension,heart_disease,smoking_history,bmi,HbA1c_level,blood_glucose_level):\n",
        "    # create a tuple from input parameters and convert them to int or float as they are treated as string when passed from Web UI\n",
        "    data = [(int(gender),int(age),int(hypertension),int(heart_disease),int(smoking_history),float(bmi),float(HbA1c_level),int(blood_glucose_level))]\n",
        "    columns = ['gender','age','hypertension','heart_disease','smoking_history','bmi','HbA1c_level','blood_glucose_level']\n",
        "\n",
        "    # Create spark dataframe for the input parameters\n",
        "    test_df = spark.createDataFrame(data,columns)\n",
        "\n",
        "    # invoke ML Model and capture model output in results\n",
        "    test_data = assembler.transform(test_df)\n",
        "    results = model.transform(test_data)\n",
        "\n",
        "    # return the results after converting it to JSON\n",
        "    return results.toJSON().first()"
      ],
      "metadata": {
        "id": "Df-lDH6cJ1o3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flask app when run gives local IP to access API. Since this is running on Cloud (Google Colab) and not on local notebook, local IP (127.0.0.1) will not be accessible.\n",
        "# Below code will ask colab to give us publicly accessible URL\n",
        "\n",
        "print(eval_js(\"google.colab.kernel.proxyPort(5000)\"))\n",
        "output.serve_kernel_port_as_window(5000)\n",
        "if __name__ == '__main__':\n",
        "    app.run(host='0.0.0.0',port=5000)"
      ],
      "metadata": {
        "id": "_nBfvcpZOmxv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}